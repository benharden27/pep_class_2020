---
title: Plotting I - Initial Tools
weight: 3
---

Data for this exercise can be found [here](../../data_raw/S258_neuston.csv).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include = TRUE, message = TRUE, warning = FALSE)
```

In this class, we will begin plotting data using [ggplot](https://ggplot2.tidyverse.org/index.html). ggplot is a powerful tool for producing elegant graphics and is relatively simple to use once you've mastered a few key ideas. We're going to be using this tool to experiment with visualizing data from a SEA Semester cruise across the South Pacific undertaken in 2014 (S258). We're going to be using a subset of the neuston net data (surface tow) from that cruise.

By the end of the class you should have:

- a pretty good handle on the various types of graphics ggplot can make
- experimented with a few different types
- advanced your thinking on how to determine the best kind of plot to make
- begun to think critically about the data sets we will be collecting
 
## Prerequisites

Before this class, you should have worked through [chapter 3](https://r4ds.had.co.nz/data-visualisation.html) of [R for Data Science](https://r4ds.had.co.nz/index.html) by Garrett Grolemund and Hadley Wickham. This should have introduced you to the basic ideas behind ggplot and helped you create your first plots using their built-in data. We're not going to take these ideas and apply them to an ocean data set.

I advise you to open a new R Script for this class (File -> New File -> R Script). You can store all the code you create in there and either run line by line (Ctrl/Cmd + Enter) or in bulk (using "play" button at top of script or by using keyboard [shortcut](https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts)). This is also useful for future reference. Don't forget to comment on your code using `#` at the start of a line to make it clear what each piece of code does.

ggplot is a package contained in the [tidyverse](https://www.tidyverse.org/) set of packages. So to run the functions contained, we first need to load the library into our work environment. You should have already installed this by running `install.packages("tidyverse")` which is a one-time action. You do however need to load the packages you need every time you restart your R session (i.e. close and reopen R Studio)

```{r, include = TRUE}
library(tidyverse)
```

This not only loads ggplot, but also other packages that we are going to use in this and other classes for tidying data sets. The "conflicts" comments are nothing to worry too much about - this is tidyverse telling us that some of the functions we just imported share names with ones already defined by R and that tidyverse will take precedent.

If you had any issues installing the complete `tidyverse`, we'll also be able to do all the exercises contained here by just loading the following libraries:

```{r}
library(ggplot2)
library(readr)
```


## Reading in the data

You need to go get the data from the top of this page and save it somewhere sensible on your computer (not your Desktop please). Once you have the data where you want it, look at it in a text editor (TextEdit, wordpad, etc.). It's a Comma-Separated-Value file (CSV) which is one of the most common data formats used for sharing data in a way that can be useful across platforms. As the name suggests, our data is organized into columns, each separated by a comma, line-by-line. The first row of our data (as in many data sets) are the names of each of the columns. If you loaded this data into Excel, it would automatically recognize this format and convert it into the standard visual layout you might expect from an Excel file.

We can read the data into our environment using `read_csv()`, a handy tool that is contained in the tidyverse packages. The only thing you *need* to tell `read_csv()` is where the CSV data file lives on your computer by way of a file path. On my computer it looks like this:

```{r read_data, include = TRUE}
df <- read_csv("~/Documents/SEA/S285_OC/dcv/R/classes/data/S258_neuston.csv")
```

You will need to replace the path I have given with the path on your computer. `read_csv()` takes in a number of other parameter if you want to fine-tune how it reads your data (look at `?read_csv()` for more details), but for our data, just the file path will suffice. As you can see from the read-out, it has even guessed at the format of each of the columns based on the data contained in the file.

Note: The tiidyverse `read_csv()` can often get confused with the basic R reader `read.csv()`. That will cause you some issues if you use the wrong one.

## Initial look at the data

The data has been imported into a **data frame** in R. Side note: Technically we're working with a tidyverse "tibble", but its built on the base R data frame, so let's not get bogged down in details at this point. I'll refer to them as data frames throughout.

Data frames are the most common way of organizing data in R and the form that ggplot requires for making plots. It's very similar to how Excel organizes data in rows and columns and, like Excel, there are a number of ways people choose to organize their data in this format. However, ggplot (and other tidyverse packages) focus on using "tidy" data: Each observation has a row and each variable is organized into a column.

```{r, fig.cap="Visualization of how values are organized in a data frame (reproduced from R for Data Science)", out.width = '100%', echo=FALSE}
knitr::include_graphics("images/tidy_1.png")
```

Lets have a look at the data we have just read in. You can either just type the name of the data frame into the console:


```{r, include = TRUE}
df
```

This gives a print out of the first 10 rows of the data and as many columns as will fit on your screen. It also gives you some more info at the bottom about number of additional rows and columns not displayed.

This can be a good way to get a quick glance at the data, but if we want to look more closely we can use a more typical spreadsheet viewer. Note the capital "V" in `View()` below.

```{r view, include = TRUE, eval = FALSE}
View(df)
```

This allows you to scroll along your data by row and column like you would in Excel.

Another great way to get a quick look at data in a data frame is to create a summary.

```{r, include = TRUE}
summary(df)
```

This gives us a bunch of statistical data on each of the columns that aren't full of characters -- min, max, quartiles, etc.

So, from these quick-looks we can begin to describe our data set:

- Each row is a neuston net tow/station. The stations are labeled in the format *cruiseID-stationNumber-deploymentType* (i.e. S258-011-NT) where NT stands for Neuston Tow.
- The other columns are:
    + dttm: date and time (in R's special datetime format)
    + lon: Longitude (decimal degrees east of 0)
    + lat: Latitude (decimal degrees north of 0)
    + temp: Surface temperature (^o^C)
    + sal: Surface salinity (PSU)
    + fluor: Surface fluorescence (Volts - a measure of chlorophyll-a concentration)
    + moon_phase: Phase of the moon from completely full (100) to completely new (0)
    + moon_mode: Whether the moon was "set" or "risen" at the time of the cast
    + tow_dist: The distance that we towed the net for (meters)
    + biomass: Biovolume of zooplankton (< 2cm) captured in net (mL)
    + nekt_total_num: Number of Nekton (> 2cm) captured in the net (#)
    + nekt_total_vol: Total Biovolume of Nekton (> 2cm) captured in the net (mL)
    + daynight: Whether the station was at "night" or during the "day"

### Other things to know about looking at data

To get the number of rows in a data frame you can use

```{r, include = TRUE}
nrow(df)
```

and same for columns.

```{r, include = TRUE}
ncol(df)
```

You can also get all the names of columns:

```{r, include = TRUE}
names(df)
```

If you want to access just one column of the data you can either access it with combinations of `$`, `[]` or `[[]]`, and reference by name of the number of the column. The first set returns a vector of the values in the column:

```{r, include = TRUE}
df$temp
df[["temp"]]
df[[5]]
```

This second set return a single column data frame:

```{r, include = TRUE}
df["temp"]
df[5]
```


## Initial plots

We don't have to do anything to organize this data at this point as I've already done that. In the future we're probably going to have to wrangle a few columns, but for now, lets focus on making some plots.

Recall from what you've already seen that we create a simple ggplot by specifying three things:

1. The data
2. The mapping of variables to aesthetics
3. A geom to represent these aesthetics

So, as a first example, we can plot the temperature data over time in the following way:

```{r, include = TRUE}
ggplot(data = df) +
  geom_line(aes(x = dttm, y = temp))
```

Where we have specified that:

1. our data is contained in the data frame, `df`
2. we want dttm on the x axis and temp on the y axis
3. we want the representation to be a line `geom_line()`

This is the most verbose way I can write this. I have used `data = df`, `x = dttm` and `y = temp`. As with many functions in R, both `ggplot()` and `aes()` are expecting certain inputs and instead of officially declaring them, you can just write them in the right order. The above code could be written more succinctly as:


```{r, eval = FALSE, include = TRUE}
ggplot(df) +
  geom_line(aes(dttm, temp))
```

We've lost something in the ability for us to directly interpret what is being assigned to what, but we're saving our fingers in the long run.

I should also note that ggplot gives you flexibility to define your data and aesthetic mappings at a number of different places. The following all do the same thing.

```{r, include = TRUE, eval = FALSE}
ggplot(df, aes(dttm, temp)) +
  geom_line()
ggplot(df) +
  geom_line(aes(dttm,temp))
ggplot() +
  geom_line(aes(dttm,temp), data = df)
```

This just gives you some more flexibility about creating plots that combine data from multiple data sets.

You can also assign a ggplot to an object as you would a vector or character string:

```{r, include = TRUE}
g <- ggplot(df, aes(dttm,temp)) +
  geom_line()
```

Doing this does *not* generate the plot, it just creates a ggplot object that can be deployed later by calling it by name or by adding another geom (for example a smoothing geom):

```{r, include = TRUE}
g
g + geom_smooth()
```

## Exercises

OK, from here-on-in, I'm going to set you some exercises to grapple with. Complete answers to come at end of class don't worry. Get through as much as you can in class and complete the rest for homework.

This is really just a forum for you to practice, experiment, break stuff and fix it. Feel free to diverge from my plan below as opportunities present themselves and you interest dictates. Plot different variables, explore the data set, have some fun.

Some tips:

- You should use the homework chapter as a good source of information to help you complete the exercises.
- Use `?function_name` to see the help file for this function. It can help you understand what you *need* to specify, what you *can* specify, and many have good examples.
- keep the ggplot cheat sheet handy as this breaks down the geoms really well.

Let's examine the amount of zooplankton we caught in each tow.

> Examine the amount of zooplankton we caught in each tow. Plot the frequency distribution of the data using `geom_histogram`. Remember, you can (and should) specify the `binwidth` parameter in the geom. (This histogram will show you the number of casts for which a certain amount of biomass was caught). What does the distribution look like? Is it pretty even (i.e. as many casts with lots of biomass as with few)?

```{r}
ggplot(df, aes(biomass)) +
  geom_histogram(binwidth = 5)
```


Histograms can give you a good sense of the distribution of your data but if you want to see each data point explicitly, you need to make a plot where you can resolve each point.

> Plot the biomass data as a function of time using points to plot each data value. Compare this plot to your histogram. Can you reconcile the two ways of looking at the same data? How is the spread of data in the histogram shown in your time series?

```{r}
ggplot(df, aes(dttm, biomass)) +
  geom_point()
```

> Experiment with plotting this biomass data using other relevent geoms for continuous data - i.e. `geom_line()`, `geom_path()`, `geom_area()`

```{r}
ggplot(df, aes(dttm, biomass)) +
  geom_area()
```

These are standard time series - they show us the change in a value over time. However, time might not be our most important factor in the kind of oceanography we'll be doing (a cruise typically can be thought of taking a snapshot over a wider region) so we might instead choose to plot against location.

> Plot fluoroesence against latitude using points. This will produce a clearer relationship than the biomass data will show. Add on a smooth line to track that broader change. What does this tell us about how many phytoplankton are in the water as we move along our cruise track? Why might that be?

```{r}
ggplot(df, aes(lat, fluor)) +
  geom_point() +
  geom_smooth()
```

What about how day and night differ? We can get at this by introducing another aesthetic such as color or shape.

> Make a similar plot of fluoroesence vs latitude, but this time add a "color"" aesthetic to be the "daynight"" parameter. Add a smoothing geom too. NB: If you define the color aesthetic in the call to ggplot(), then the geom_smooth will also automatically assign itself to these two categories. Try it again with assigning the aesthetic to "shape". One thing you will notice is that ggplot will automatically assign a legend for you. Hurray!

What patterns do you see? Do you think you'd see similar patterns in the amount of biomass between day and night?

```{r}
ggplot(df, aes(lat, fluor, color = daynight)) +
  geom_point() + 
  geom_smooth()

ggplot(df, aes(lat, fluor, shape = daynight)) +
  geom_point() + 
  geom_smooth(aes(linetype = daynight), color = "black")
```

> Do the same plotting for biomass. Is the pattern the same?

```{r}
ggplot(df, aes(lat, biomass, color = daynight)) +
  geom_point() + 
  geom_smooth()
```

Another way to look at the differences between night and day is to facet the plots (i.e. creates subplots with data that meet different criteria on each)

> Use facet_wrap() to create facets for each of "day" and "night" for fluoroescence as a function of latitude.

```{r}
ggplot(df, aes(lat, fluor)) +
  geom_point() + 
  geom_smooth() +
  facet_wrap(~daynight)

```


Another way to explore this data might be in a box plot across the whole data set:

> Create a boxplot for each of "day" and "night" for biomass data

```{r}
ggplot(df, aes(daynight, biomass)) +
  geom_boxplot()
```

The outliers make this a little hard to interpret -- how would we go about zooming in a little on the y axis? For x and y axis zooming, we basically have two options.

1. We can scale the data such that we cut off values above or below a certain value using the `xlim` and `ylim` functions. In our case we will use, for example `ylim(0,100)` 
2. We can simply "zoom in" without removing data using the `coord_cartesian()` function. In our case this will be `coord_cartesian(ylim = c(0,100))`

The choice you make will sometimes make a big difference depending on what data you are plotting. In our case it will make a difference.

> Try both methods of zooming in on the y axis - what difference does it make which method you use?

```{r}
ggplot(df, aes(daynight, biomass)) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0,100))

ggplot(df, aes(daynight, biomass)) +
  geom_boxplot() +
  ylim(0,100)

```


## Additional activities

Is biomass a good value to compare between stations? What might be a better metric for comparison of the amount of zooplankton between regions? How would you go about making this new data? Hint: Explore the tow_dist column a little.

How would you test the relationship between the amount of biomass and the amount of phytoplankton? Look at the options within geom_smooth to see about how to plot a regression line.

```{r}
ggplot(df, aes(fluor, biomass/tow_dist)) +
  geom_point() +
  geom_smooth(method='lm') +
  coord_cartesian(ylim = c(0,0.25))
```


